services:
  tabbyapi-base:
    # Uncomment this to build a docker image from source
    # build:
    #   context: .
    #   dockerfile: ./Dockerfile
    #   target: tabbyapi-exllamav2-builder-image-runtime

    # Comment this to build a docker image from source
    image: gitlab-registry.rancher.devguy.dev/davidallada/llm-gpu-clone
    runtime: nvidia
    privileged: true # Required for mounting NFS
    volumes:
      - pip-cache:/cache/pip
      - apt-cache:/cache/apt
      - /mnt/docker_data/llm-repo/tabby_data:/app/tabby_data
      - /mnt/docker_data/llm-repo/model_directories:/app/model_directories
    command: exit

  tabbyapi:
    extends:
      service: tabbyapi-base
    container_name: tabbyapi-webserver
    restart: always
    environment:
      - NAME=TabbyAPI
      - NVIDIA_VISIBLE_DEVICES=0,1
      - GGUF_STORAGE_DIR=/mnt/exllamav2/gguf
      - EXL2_STORAGE_DIR=/mnt/exllamav2/exl2
      - MEASUREMENT_JSON_DIR=/mnt/exllamav2/measurement_json
    ports:
      - "5000:5000"
      - "8076:8888"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    command: webserver

  tabbyapi-converter:
    restart: always
    extends:
      service: tabbyapi-base
    ports:
      - "5001:5000"
      - "8077:8888"
    command: converter
    environment:
      - NAME=TabbyAPI
      - NVIDIA_VISIBLE_DEVICES=0,1
      - GGUF_STORAGE_DIR=/mnt/exllamav2/gguf
      - EXL2_STORAGE_DIR=/mnt/exllamav2/exl2
      - MEASUREMENT_JSON_DIR=/mnt/exllamav2/measurement_json

  tabbyapi-embeddings:
    restart: always
    extends:
      service: tabbyapi-base
    ports:
      - "5002:5000"
      - "8078:8888"
    command: embeddings_only
    environment:
      - NAME=TabbyAPI
      - NVIDIA_VISIBLE_DEVICES=2
      - GGUF_STORAGE_DIR=/mnt/exllamav2/gguf
      - EXL2_STORAGE_DIR=/mnt/exllamav2/exl2
      - MEASUREMENT_JSON_DIR=/mnt/exllamav2/measurement_json


# curl http://10.69.1.169:5000/v1/model/load \
#   -H "Content-Type: application/json" \
#   -H "x-api-key: <api_key>" \
#   -H "x-admin-key: <api_key>" \
#   -H "Authorization: Bearer <api_key>" \
#   -d '{
#     "model_name": "Qwen_Qwen2.5-Coder-32B-Instruct-4.0",
#     "draft_model": {
#       "draft_model_name": "Qwen_Qwen2.5-Coder-0.5B-Instruct-4.0-bpw"
#     }
#   }'


volumes:
  pip-cache:
  apt-cache:
