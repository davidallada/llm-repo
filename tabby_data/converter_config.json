{
    "model_configs": [
        {
            "model_name": "Alibaba-NLP/gte-Qwen2-1.5B-instruct",
            "bpw": []
        },
        {
            "model_name": "sesame/csm-1b",
            "bpw": []
        },
        {
            "model_name": "CohereForAI/c4ai-command-a-03-2025",
            "bpw": [4.0, 5.2]
        },
        {
            "model_name": "nvidia/Llama-3_3-Nemotron-Super-49B-v1",
            "bpw": [5.2, 6.0]
        },
        {
            "model_name": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
            "bpw": [5.2, 8.0]
        },
        {
            "model_name": "google/gemma-3-27b-it",
            "bpw": [5.2, 8.0]
        },
        {
            "model_name": "google/gemma-3-12b-it",
            "bpw": [5.2, 8.0]
        },
        {
            "model_name": "google/gemma-3-4b-it",
            "bpw": [5.2, 8.0]
        },
        {
            "model_name": "microsoft/Phi-4-multimodal-instruct",
            "bpw": [5.2, 8.0]
        },
        {
            "model_name": "microsoft/OmniParser-v2.0",
            "bpw": [5.2, 8.0]
        },
        {
            "model_name": "InfiniAILab/QwQ-0.5B",
            "bpw": [5.2, 5.5, 6.0, 6.5, 8.0]
        },
        {
            "model_name": "Qwen/QwQ-32B",
            "bpw": [5.2, 5.5, 6.0, 6.5, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-VL-72B-Instruct",
            "bpw": [4.0, 4.5, 5.2]
        },
        {
            "model_name": "watt-ai/watt-tool-70B",
            "bpw": [4.0, 5.2]
        },
        {
            "model_name": "watt-ai/watt-tool-8B",
            "bpw": [4.0, 5.2, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-VL-7B-Instruct",
            "bpw": [4.0, 5.2, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-VL-3B-Instruct",
            "bpw": [4.0, 5.2, 8.0]
        },
        {
            "model_name": "internlm/internlm3-8b-instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "PowerInfer/SmallThinker-3B-Preview",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
            "bpw": [4.0, 4.5, 5.2]
        },
        {
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-Coder-0.5B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-Coder-1.5B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-Coder-3B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-Coder-7B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-Coder-14B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-Coder-32B-Instruct",
            "bpw": [3.0, 3.5, 4.0, 4.5, 4.8, 5.0, 5.2, 5.25, 5.5, 6.0, 6.25, 6.5, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-32B-Instruct",
            "bpw": [3.0, 3.5, 4.0, 5.2, 6.0, 6.25, 6.5, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-14B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-7B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-3B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-1.5B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-0.5B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/QwQ-32B-preview",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "bpw": [2.0, 2.5, 3.0, 3.5, 4.0, 5.2]
        },
        {
            "model_name": "meta-llama/Llama-3.3-70B-Instruct",
            "bpw": [2.0, 2.5, 3.0, 3.5, 4.0, 5.2]
        },
        {
            "model_name": "meta-llama/Llama-3.1-8B-Instruct",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "bpw": [4.0]
        },
        {
            "model_name": "answerdotai/ModernBERT-base",
            "bpw": []
        },
        {
            "model_name": "answerdotai/ModernBERT-large",
            "bpw": []
        },
        {
            "model_name": "google/Gemma-Embeddings-v1.0",
            "bpw": []
        },
        {
            "model_name": "dunzhang/stella_en_1.5B_v5",
            "bpw": []
        },
        {
            "model_name": "nvidia/NV-Embed-v2",
            "bpw": []
        },
        {
            "model_name": "Qwen/Qwen2.5-72B-Instruct",
            "bpw": [2.0, 2.5, 3.0, 3.5, 4.0, 4.25, 5.2]
        },
        {
            "model_name": "Qwen/QVQ-72B-preview",
            "bpw": [2.0, 2.5, 3.0, 3.5, 4.0, 5.2]
        },
        {
            "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
            "bpw": [4.0, 5.2, 6.5]
        },
        {
            "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
            "bpw": [4.0, 5.2, 6.5]
        },
        {
            "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
            "bpw": [4.0, 5.2, 8.0]
        },
        {
            "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
            "bpw": [4.0, 5.2, 6.5, 8.0]
        },
        {
            "model_name": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
            "bpw": [4.0, 4.25, 5.2]
        },
        {
            "model_name": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
            "bpw": [4.0, 5.2, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-14B-Instruct-1M",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "Qwen/Qwen2.5-7B-Instruct-1M",
            "bpw": [4.0, 5.2, 6.0, 8.0]
        },
        {
            "model_name": "nvidia/Llama-3.1-8B-UltraLong-1M-Instruct",
            "bpw": [5.2, 8.0]
        },
        {
            "model_name": "nvidia/Llama-3.1-8B-UltraLong-2M-Instruct",
            "bpw": [5.2, 8.0]
        },
        {
            "model_name": "nvidia/Llama-3.1-8B-UltraLong-4M-Instruct",
            "bpw": [5.2, 8.0]
        },
        {
            "model_name": "nvidia/Llama-3.1-Nemotron-Nano-8B-v1",
            "bpw": [5.2, 8.0]
        },
        {
            "model_name": "deepseek-ai/DeepSeek-V3",
            "bpw": []
        },
        {
            "model_name": "AtlaAI/Selene-1-Mini-Llama-3.1-8B",
            "bpw": []
        },
        {
            "model_name": "openai/whisper-large-v3-turbo",
            "bpw": []
        },
        {
            "model_name": "hexgrad/Kokoro-TTS",
            "bpw": []
        }
    ]
}
