{
    "model_configs": [
        {
            "pretty_model_name": "Qwen2.5-Coder-32B-single-GPU-12k",
            "model_name": "Qwen_Qwen2.5-Coder-32B-Instruct-4.0-bpw",
            "draft_model": "Qwen_Qwen2.5-Coder-1.5B-Instruct-4.0-bpw",
            "tabby_config": {
                "max_seq_len": 12288
            },
            "comment": "Fits in one GPU with decent context"
        },
        {
            "pretty_model_name": "Qwen2.5-Coder-32B-daily-6.5bpw-32k",
            "model_name": "Qwen_Qwen2.5-Coder-32B-Instruct-6.5-bpw",
            "draft_model": "Qwen_Qwen2.5-Coder-1.5B-Instruct-4.0-bpw",
            "tabby_config": {
                "max_seq_len": 32768
            },
            "comment": "Daily Driver, Full context, fits in 2 GPU's"
        },
        {
            "pretty_model_name": "Qwen2.5-Coder-32B-daily-6.0bpw-32k",
            "model_name": "Qwen_Qwen2.5-Coder-32B-Instruct-6.0-bpw",
            "draft_model": "Qwen_Qwen2.5-Coder-1.5B-Instruct-4.0-bpw",
            "tabby_config": {
                "max_seq_len": 32768
            },
            "comment": "Daily Driver, Full context, fits in 2 GPU's -- with 6.0 haha"
        },
        {
            "pretty_model_name": "Qwen2.5-Coder-32B-100k-context",
            "model_name": "Qwen_Qwen2.5-Coder-32B-Instruct-4.0-bpw",
            "draft_model": "Qwen_Qwen2.5-Coder-1.5B-Instruct-4.0-bpw",
            "tabby_config": {
                "max_seq_len": 100096
            },
            "comment": "Daily Driver, Full context, fits in 2 GPU's -- with 6.0 haha"
        },
        {
            "pretty_model_name": "Qwen2.5-Coder-32B-128k-context",
            "model_name": "Qwen_Qwen2.5-Coder-32B-Instruct-4.0-bpw",
            "draft_model": "Qwen_Qwen2.5-Coder-1.5B-Instruct-4.0-bpw",
            "tabby_config": {
                "max_seq_len": 128000
            },
            "comment": "Daily Driver, Full context, fits in 2 GPU's -- with 6.0 haha"
        },
        {
            "pretty_model_name": "Qwen2.5-72B-12k",
            "model_name": "Qwen_Qwen2.5-72B-Instruct-4.0-bpw",
            "draft_model": "Qwen_Qwen2.5-Coder-1.5B-Instruct-4.0-bpw",
            "tabby_config": {
                "max_seq_len": 12288
            },
            "comment": "Qwen 2.5 72B fits in two GPU's with 12k context"
        },

        {
            "pretty_model_name": "Qwen_QVQ-72B-preview-4.0-bpw",
            "model_name": "Qwen_QVQ-72B-preview-4.0-bpw",
            "draft_model": "",
            "tabby_config": {
                "max_seq_len": 12288
            },
            "comment": "QVQ"
        },

        {
            "pretty_model_name": "QwQ-Preview-32B",
            "model_name": "Qwen_QwQ-32B-preview-6.0-bpw",
            "draft_model": "",
            "tabby_config": {
                "max_seq_len": 32768
            },
            "comment": "QwQ Preview"
        },

        {
            "pretty_model_name": "QwQ-Preview-32B-draft",
            "model_name": "Qwen_QwQ-32B-preview-6.0-bpw",
            "draft_model": "PowerInfer_SmallThinker-3B-Preview-4.0-bpw",
            "tabby_config": {
                "max_seq_len": 32768
            },
            "comment": "QwQ Preview"
        },
        {
            "pretty_model_name": "homeassistant-llama-8b-4bpw-8k",
            "model_name": "meta-llama_Llama-3.1-8B-Instruct-4.0-bpw",
            "draft_model": "",
            "tabby_config": {
                "max_seq_len": 8192
            },
            "comment": "For homeassistant"
        },
        {
            "pretty_model_name": "llama-8B-4bpw-fast-32k",
            "model_name": "meta-llama_Llama-3.1-8B-Instruct-4.0-bpw",
            "draft_model": "",
            "tabby_config": {
                "max_seq_len": 32768
            },
            "comment": "Super fast 150 tokens/sec"
        },
        {
            "pretty_model_name": "llama-8B-8bpw-32k",
            "model_name": "meta-llama_Llama-3.1-8B-Instruct-8.0-bpw",
            "draft_model": "",
            "tabby_config": {
                "max_seq_len": 32768
            },
            "comment": "Higher quality llama 8B with 32k context"
        },
        {
            "pretty_model_name": "llama-8B-4bpw-fast-128k",
            "model_name": "meta-llama_Llama-3.1-8B-Instruct-4.0-bpw",
            "draft_model": "",
            "tabby_config": {
                "max_seq_len": 128000
            },
            "comment": "Super long context"
        },
        {
            "pretty_model_name": "llama-8B-8bpw-128k",
            "model_name": "meta-llama_Llama-3.1-8B-Instruct-8.0-bpw",
            "draft_model": "",
            "tabby_config": {
                "max_seq_len": 128000
            },
            "comment": "Super long contex"
        },
        {
            "pretty_model_name": "Llama-3.3-70B-draft",
            "model_name": "meta-llama_Llama-3.3-70B-Instruct-4.0-bpw",
            "draft_model": "meta-llama_Llama-3.2-1B-Instruct-4.0-bpw",
            "tabby_config": {
                "max_seq_len": 8192
            },
            "comment": "Big LLama"
        }
    ],
    "embedding_configs": [
        {
            "pretty_model_name": "dunzhang_stella_en_1.5B_v5",
            "model_name": "dunzhang_stella_en_1.5B_v5",
            "comment": "Stella"
        },
        {
            "pretty_model_name": "google_Gemma-Embeddings-v1.0",
            "model_name": "google_Gemma-Embeddings-v1.0",
            "comment": "Gemma"
        },
        {
            "pretty_model_name": "answerdotai_ModernBERT-large",
            "model_name": "answerdotai_ModernBERT-large",
            "comment": "ModernBERT"
        }
    ],
    "lora_configs": []
}
